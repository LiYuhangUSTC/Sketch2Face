# Sketch2Face

Work in progress...

This is the official implementation of paper DeepFacePencil: Creating Face Images from Freehand Sketches. [arXiv Link](arXiv Link) [Project](Project Link)

![overview](figures/overview.png "overview")

### Prerequisites
PyTorch 1.6, Python 3.7, NumPy, scipy, PIL, tqdm

### Data
We use [CelebAMask-HQ](https://github.com/switchablenorms/CelebAMask-HQ) to obtain synthesized (boundary) sketches. Deformed sketches are generated by vectorizing synthesized sketches using [AutoTrace](http://autotrace.sourceforge.net/) and adding random offsets to endpoints and control points of vectorized strokes.

### Pretrained model
[GoogleDrive (comming soon)](), and [BaiduPan (comming soon)]()

### Test
The test sketches should be put in folder `./datasets/CelebAMask/test_A`. The pretrained model should be put in folder `./checkpoints/pretrained`. Example script of testing can be found in `./test_scripts.sh`. The results are supposed to be in `./results`.

### Cite
```

```

### Credits
This code borrows heavily from [pix2pixHD](https://github.com/NVIDIA/pix2pixHD) and [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).
